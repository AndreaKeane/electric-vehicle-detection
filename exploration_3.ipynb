{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Setup\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import utilities as utils\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame Shapes\n",
      "Test: (699, 2880)\n",
      "Train: (1590, 2880)\n",
      "Labels: (1590, 2880)\n"
     ]
    }
   ],
   "source": [
    "# Import test, train, label data into dataframes\n",
    "test, train, labels = utils.get_raw_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers: 37\n",
      "Percent Removed: 2.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine outliers\n",
    "outliers = utils.classify_outliers(train)\n",
    "\n",
    "# Drop Outliers\n",
    "train_clean = train.drop(outliers.index)\n",
    "labels_clean = labels.drop(outliers.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Feature Engineering\n",
    "A series with significant dependence among values. In this case we need to use some statistical models like ARIMA to forecast the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553\n"
     ]
    }
   ],
   "source": [
    "# Select random subset of houses\n",
    "rand_house = random.choices(train_clean.index.tolist(), k=500)\n",
    "full_set = train_clean.index.tolist()\n",
    "print(len(full_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24-hour average\n",
    "feat_24h_avg = train.rolling(window=(24*2), axis=1).mean()\n",
    "\n",
    "# Difference from preceding interval\n",
    "feat_diff = train.diff(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4471920\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "                      value   diff   day_avg  label\n",
      "House ID                                           \n",
      "11655099 Interval_1   0.950    NaN       NaN    0.0\n",
      "         Interval_2   0.826 -0.124       NaN    0.0\n",
      "         Interval_3   0.361 -0.465       NaN    0.0\n",
      "         Interval_4   0.238 -0.123       NaN    0.0\n",
      "         Interval_5   0.342  0.104       NaN    0.0\n",
      "         Interval_6   0.233 -0.109       NaN    0.0\n",
      "         Interval_7   0.351  0.118       NaN    0.0\n",
      "         Interval_8   0.194 -0.157       NaN    0.0\n",
      "         Interval_9   0.292  0.098       NaN    0.0\n",
      "         Interval_10  0.234 -0.058       NaN    0.0\n",
      "         Interval_11  0.260  0.026       NaN    0.0\n",
      "         Interval_12  0.274  0.014       NaN    0.0\n",
      "         Interval_13  0.192 -0.082       NaN    0.0\n",
      "         Interval_14  0.329  0.137       NaN    0.0\n",
      "         Interval_15  0.192 -0.137       NaN    0.0\n",
      "         Interval_16  0.443  0.251       NaN    0.0\n",
      "         Interval_17  0.260 -0.183       NaN    0.0\n",
      "         Interval_18  0.222 -0.038       NaN    0.0\n",
      "         Interval_19  0.419  0.197       NaN    0.0\n",
      "         Interval_20  0.249 -0.170       NaN    0.0\n",
      "         Interval_21  0.429  0.180       NaN    0.0\n",
      "         Interval_22  0.426 -0.003       NaN    0.0\n",
      "         Interval_23  0.373 -0.053       NaN    0.0\n",
      "         Interval_24  0.335 -0.038       NaN    0.0\n",
      "         Interval_25  0.457  0.122       NaN    0.0\n",
      "         Interval_26  1.199  0.742       NaN    0.0\n",
      "         Interval_27  1.735  0.536       NaN    0.0\n",
      "         Interval_28  1.431 -0.304       NaN    0.0\n",
      "         Interval_29  1.151 -0.280       NaN    0.0\n",
      "         Interval_30  1.258  0.107       NaN    0.0\n",
      "         Interval_31  1.243 -0.015       NaN    0.0\n",
      "         Interval_32  0.825 -0.418       NaN    0.0\n",
      "         Interval_33  0.534 -0.291       NaN    0.0\n",
      "         Interval_34  0.513 -0.021       NaN    0.0\n",
      "         Interval_35  0.775  0.262       NaN    0.0\n",
      "         Interval_36  0.708 -0.067       NaN    0.0\n",
      "         Interval_37  0.655 -0.053       NaN    0.0\n",
      "         Interval_38  0.618 -0.037       NaN    0.0\n",
      "         Interval_39  0.600 -0.018       NaN    0.0\n",
      "         Interval_40  0.577 -0.023       NaN    0.0\n",
      "         Interval_41  0.568 -0.009       NaN    0.0\n",
      "         Interval_42  0.550 -0.018       NaN    0.0\n",
      "         Interval_43  0.351 -0.199       NaN    0.0\n",
      "         Interval_44  0.431  0.080       NaN    0.0\n",
      "         Interval_45  0.202 -0.229       NaN    0.0\n",
      "         Interval_46  0.311  0.109       NaN    0.0\n",
      "         Interval_47  0.679  0.368       NaN    0.0\n",
      "         Interval_48  0.852  0.173  0.555146    0.0\n",
      "         Interval_49  0.887  0.035  0.553833    0.0\n",
      "         Interval_50  0.776 -0.111  0.552792    0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pfolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74f4aa4ca4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/andreakeane/Documents/DataScience/GridCure_Problems/EV_files/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfolder\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'features.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pfolder' is not defined"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame(index=train_clean.stack().index)\n",
    "print(features.shape[0])\n",
    "for i, index in enumerate(features.index.tolist()): \n",
    "    house_id, interval = index\n",
    "    features.at[index, 'value'] = train[interval].loc[house_id]\n",
    "    features.at[index, 'diff'] = feat_diff[interval].loc[house_id]\n",
    "    features.at[index, 'day_avg'] = feat_24h_avg[interval].loc[house_id]  \n",
    "    features.at[index, 'label'] = labels_clean[interval].loc[house_id]  \n",
    "    if i % 1000000 == 0: print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "folder = Path('/Users/andreakeane/Documents/DataScience/GridCure_Problems/EV_files/')\n",
    "features.to_csv(folder / 'features.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504585 Rows were dropped for NA reasons.\n"
     ]
    }
   ],
   "source": [
    "# Split into features and classifications\n",
    "X = features[['diff', 'value', 'day_avg']]\n",
    "y = features['label']\n",
    "\n",
    "# Drop NA-containing rows from X\n",
    "before = set(X.index.tolist())\n",
    "X = X.dropna(axis=0)\n",
    "after = set(X.index.tolist())\n",
    "removed_id = before - after\n",
    "print(\"{} Rows were dropped for NA reasons.\".format(len(removed_id)))\n",
    "\n",
    "# Drop corresponsing rows from y\n",
    "y = y.drop(index=removed_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier on test set: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Scale X-data between -1 and 1\n",
    "scaler = StandardScaler().fit(X)                                    \n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.89212656e-01, 1.07873438e-02],\n",
       "       [9.99942115e-01, 5.78848335e-05],\n",
       "       [9.83378421e-01, 1.66215794e-02],\n",
       "       ...,\n",
       "       [9.64300724e-01, 3.56992764e-02],\n",
       "       [9.95584787e-01, 4.41521292e-03],\n",
       "       [9.96475624e-01, 3.52437590e-03]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Transpose data s.t. each unique combination of house-interval is a separate row. This nested for-loop is very slow.\n",
    "# '''\n",
    "# data_points = []\n",
    "# cols = list(train.columns.values)\n",
    "\n",
    "# # For each house\n",
    "# for house_id in rand_house:\n",
    "#     # For each interval\n",
    "#     for interval in cols:\n",
    "#         temp_dict = {'house_id': house_id, \n",
    "#                      'interval': interval, \n",
    "#                      'value': train[interval].loc[house_id],\n",
    "#                      'diff': feat_diff[interval].loc[house_id], \n",
    "#                      '24h_avg': feat_24h_avg[interval].loc[house_id],\n",
    "#                      'label': labels[interval].loc[house_id]\n",
    "#                     }\n",
    "#         data_points.append(temp_dict)\n",
    "\n",
    "# features = pd.DataFrame(data_points)\n",
    "# features['label'].replace({0:False, 1:True}, inplace=True)\n",
    "\n",
    "# print(features.head())\n",
    "# print(features.shape)\n",
    "\n",
    "# # (Failed)\n",
    "# #                      '7d_avg': feat_7d_avg.at[house_id, interval],\n",
    "# #                      '24h_avg': feat_24h_avg.at[house_id, interval], \n",
    "# #                      '24h_max': feat_24h_diff.at[house_id, interval],"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
