{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import utilities as utils\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = Path('/Users/andreakeane/Documents/DataScience/GridCure_Problems/pickles/')\n",
    "\n",
    "# TODO: Put these somewhere better\n",
    "# test.to_pickle(folder / \"test.pkl\")\n",
    "# train.to_pickle(folder / \"train.pkl\")\n",
    "# labels.to_pickle(folder / \"labels.pkl\")\n",
    "\n",
    "test = pd.read_pickle(pickle_path / \"test.pkl\")\n",
    "train = pd.read_pickle(pickle_path / \"train.pkl\")\n",
    "labels = pd.read_pickle(pickle_path / \"labels.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Outliers: 37\n",
      "Percent Removed: 2.33%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Determine outliers\n",
    "outliers = utils.classify_outliers(train)\n",
    "\n",
    "# Drop Outliers\n",
    "train_clean = train.drop(outliers.index)\n",
    "labels_clean = labels.drop(outliers.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Feature Engineering\n",
    "A series with significant dependence among values. In this case we need to use some statistical models like ARIMA to forecast the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24-hour average\n",
    "feat_24h_avg = train.rolling(window=(24*2), axis=1).mean()\n",
    "\n",
    "# Difference from preceding interval\n",
    "feat_diff = train.diff(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4471920\n",
      "0\n",
      "1000000\n",
      "2000000\n",
      "3000000\n",
      "4000000\n",
      "                      value   diff   day_avg  label\n",
      "House ID                                           \n",
      "11655099 Interval_1   0.950    NaN       NaN    0.0\n",
      "         Interval_2   0.826 -0.124       NaN    0.0\n",
      "         Interval_3   0.361 -0.465       NaN    0.0\n",
      "         Interval_4   0.238 -0.123       NaN    0.0\n",
      "         Interval_5   0.342  0.104       NaN    0.0\n",
      "         Interval_6   0.233 -0.109       NaN    0.0\n",
      "         Interval_7   0.351  0.118       NaN    0.0\n",
      "         Interval_8   0.194 -0.157       NaN    0.0\n",
      "         Interval_9   0.292  0.098       NaN    0.0\n",
      "         Interval_10  0.234 -0.058       NaN    0.0\n",
      "         Interval_11  0.260  0.026       NaN    0.0\n",
      "         Interval_12  0.274  0.014       NaN    0.0\n",
      "         Interval_13  0.192 -0.082       NaN    0.0\n",
      "         Interval_14  0.329  0.137       NaN    0.0\n",
      "         Interval_15  0.192 -0.137       NaN    0.0\n",
      "         Interval_16  0.443  0.251       NaN    0.0\n",
      "         Interval_17  0.260 -0.183       NaN    0.0\n",
      "         Interval_18  0.222 -0.038       NaN    0.0\n",
      "         Interval_19  0.419  0.197       NaN    0.0\n",
      "         Interval_20  0.249 -0.170       NaN    0.0\n",
      "         Interval_21  0.429  0.180       NaN    0.0\n",
      "         Interval_22  0.426 -0.003       NaN    0.0\n",
      "         Interval_23  0.373 -0.053       NaN    0.0\n",
      "         Interval_24  0.335 -0.038       NaN    0.0\n",
      "         Interval_25  0.457  0.122       NaN    0.0\n",
      "         Interval_26  1.199  0.742       NaN    0.0\n",
      "         Interval_27  1.735  0.536       NaN    0.0\n",
      "         Interval_28  1.431 -0.304       NaN    0.0\n",
      "         Interval_29  1.151 -0.280       NaN    0.0\n",
      "         Interval_30  1.258  0.107       NaN    0.0\n",
      "         Interval_31  1.243 -0.015       NaN    0.0\n",
      "         Interval_32  0.825 -0.418       NaN    0.0\n",
      "         Interval_33  0.534 -0.291       NaN    0.0\n",
      "         Interval_34  0.513 -0.021       NaN    0.0\n",
      "         Interval_35  0.775  0.262       NaN    0.0\n",
      "         Interval_36  0.708 -0.067       NaN    0.0\n",
      "         Interval_37  0.655 -0.053       NaN    0.0\n",
      "         Interval_38  0.618 -0.037       NaN    0.0\n",
      "         Interval_39  0.600 -0.018       NaN    0.0\n",
      "         Interval_40  0.577 -0.023       NaN    0.0\n",
      "         Interval_41  0.568 -0.009       NaN    0.0\n",
      "         Interval_42  0.550 -0.018       NaN    0.0\n",
      "         Interval_43  0.351 -0.199       NaN    0.0\n",
      "         Interval_44  0.431  0.080       NaN    0.0\n",
      "         Interval_45  0.202 -0.229       NaN    0.0\n",
      "         Interval_46  0.311  0.109       NaN    0.0\n",
      "         Interval_47  0.679  0.368       NaN    0.0\n",
      "         Interval_48  0.852  0.173  0.555146    0.0\n",
      "         Interval_49  0.887  0.035  0.553833    0.0\n",
      "         Interval_50  0.776 -0.111  0.552792    0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pfolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-74f4aa4ca4d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/andreakeane/Documents/DataScience/GridCure_Problems/EV_files/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfolder\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'features.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pfolder' is not defined"
     ]
    }
   ],
   "source": [
    "features = pd.DataFrame(index=train_clean.stack().index)\n",
    "print(\"Total anticipated rows: {}\".format(features.shape[0]))\n",
    "for i, index in enumerate(features.index.tolist()): \n",
    "    house_id, interval = index\n",
    "    features.at[index, 'value'] = train[interval].loc[house_id]\n",
    "    features.at[index, 'diff'] = feat_diff[interval].loc[house_id]\n",
    "    features.at[index, 'day_avg'] = feat_24h_avg[interval].loc[house_id]  \n",
    "    features.at[index, 'label'] = labels_clean[interval].loc[house_id]  \n",
    "    if i % 1000000 == 0: print(i)\n",
    "\n",
    "features.to_pickle(pickle_path / \"features.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72991 Rows were dropped for NA reasons.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a clean version of features\n",
    "features = pd.read_pickle(pickle_path / \"features.pkl\")\n",
    "\n",
    "# Split into features and classifications\n",
    "X = features[['diff', 'value', 'day_avg']]\n",
    "y = features['label']\n",
    "\n",
    "# Drop NA-containing rows from X\n",
    "before = set(X.index.tolist())\n",
    "X = X.dropna(axis=0)\n",
    "after = set(X.index.tolist())\n",
    "removed_id = before - after\n",
    "print(\"{} Rows were dropped for NA reasons.\".format(len(removed_id)))\n",
    "\n",
    "# Drop corresponsing rows from y\n",
    "y = y.drop(index=removed_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of classifier on test set: 0.977\n"
     ]
    }
   ],
   "source": [
    "# Scale X-data between -1 and 1\n",
    "scaler = StandardScaler().fit(X)                                    \n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=0)\n",
    "\n",
    "# Train logistic regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=0)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.89212656e-01, 1.07873438e-02],\n",
       "       [9.99942115e-01, 5.78848335e-05],\n",
       "       [9.83378421e-01, 1.66215794e-02],\n",
       "       ...,\n",
       "       [9.64300724e-01, 3.56992764e-02],\n",
       "       [9.95584787e-01, 4.41521292e-03],\n",
       "       [9.96475624e-01, 3.52437590e-03]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>bool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>House ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11655099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11633257</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11651552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11636092</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11647239</th>\n",
       "      <td>117.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sum  bool\n",
       "House ID             \n",
       "11655099    0.0   0.0\n",
       "11633257    0.0   0.0\n",
       "11651552    0.0   0.0\n",
       "11636092    0.0   0.0\n",
       "11647239  117.0   1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results Testing\n",
    "labels_mod = features['label'].unstack()\n",
    "labels_mod = pd.DataFrame(labels_mod.sum(axis=1))\n",
    "labels_mod.rename(columns= {0: 'sum'}, inplace=True)\n",
    "labels_mod['bool'] = labels_mod['sum'].where(labels_mod['sum'] == 0, other=1)\n",
    "\n",
    "labels_mod.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
